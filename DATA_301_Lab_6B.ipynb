{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jhhhz4ntYUM"
      },
      "source": [
        "# Kaggle Competition\n",
        "\n",
        "The goal of machine learning is to build models with high predictive accuracy. Thus, it is not surprising that there exist machine learning competitions, where participants compete to build the model with the lowest possible prediction error.\n",
        "\n",
        "[Kaggle](http://www.kaggle.com/) is a website that hosts machine learning competitions. In this lab, you will participate in a Kaggle competition with other students in this class!  To join the competition, visit [this link](https://www.kaggle.com/t/0de6e5c147c84833a7338e6adcc1ed37). You will need to register an account with Kaggle, but you can use your Google account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6K8JJuRtYUP"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Train many different models to predict IBU. Try different subsets of variables. Try different machine learning algorithms (you are not restricted to just $k$-nearest neighbors). At least one of your models must contain variables derived from the `description` of each beer. Use cross-validation to systematically select good models and submit your predictions to Kaggle. You are allowed 2 submissions per day, so submit early and often!\n",
        "\n",
        "Note that to submit your predictions to Kaggle, you will need to export your predictions to a CSV file (using `.to_csv()`) in the format expected by Kaggle (see `beer_test_sample_submission.csv` for an example)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import numpy as np\n",
        "\n",
        "train_url = 'https://dlsun.github.io/pods/data/beer/beer_train.csv'\n",
        "data = pd.read_csv(train_url)\n",
        "\n",
        "data = data[data['srm'] != 'Over 40']\n",
        "data['srm'] = pd.to_numeric(data['srm'])\n",
        "\n",
        "data.dropna(inplace = True)\n",
        "\n",
        "\n",
        "test_url = 'https://dlsun.github.io/pods/data/beer/beer_test.csv'\n",
        "test_data = pd.read_csv(test_url)\n",
        "\n",
        "\n",
        "test_data['abv'].fillna(test_data['abv'].mean(), inplace=True)\n",
        "test_data['name'].fillna('unknown', inplace=True)\n",
        "test_data['available'].fillna('unknown', inplace=True)\n",
        "test_data['glass'].fillna('unknown', inplace=True)\n",
        "test_data['description'].fillna('No description available', inplace=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIxlmBbANxpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_subsets = [\n",
        "    [\"abv\"],\n",
        "    [\"abv\", \"name\"],\n",
        "    [\"abv\", \"name\", \"available\"],\n",
        "    [\"abv\", \"name\", \"available\", \"glass\"],\n",
        "    [\"abv\", \"name\", \"description\"],\n",
        "    [\"abv\", \"name\", \"available\", \"glass\", \"description\"],\n",
        "    [\"abv\", \"originalGravity\"],\n",
        "    [\"abv\", \"srm\"],\n",
        "    [\"abv\", \"isOrganic\"],\n",
        "    [\"abv\", \"name\", \"description\", \"originalGravity\", \"srm\", \"isOrganic\"]\n",
        "]\n",
        "\n",
        "target = \"ibu\"\n",
        "\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"ElasticNet\": ElasticNet(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"LinearRegression\": {},\n",
        "    \"Ridge\": {'model__alpha': [0.1, 1.0, 10.0, 100.0]},\n",
        "    \"Lasso\": {'model__alpha': [0.1, 1.0, 10.0, 100.0]},\n",
        "    \"ElasticNet\": {'model__alpha': [0.1, 1.0, 10.0], 'model__l1_ratio': [0.1, 0.5, 0.9]},\n",
        "    \"DecisionTreeRegressor\": {'model__max_depth': [5, 10, 20]},\n",
        "    \"RandomForestRegressor\": {'model__n_estimators': [100, 200], 'model__max_depth': [5, 10, 20]},\n",
        "    \"GradientBoostingRegressor\": {'model__n_estimators': [100, 200], 'model__learning_rate': [0.01, 0.1, 0.2]},\n",
        "}\n"
      ],
      "metadata": {
        "id": "H1Pn8JcJiAe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    for feature_set in feature_subsets:\n",
        "        transformers = []\n",
        "\n",
        "        if \"abv\" in feature_set:\n",
        "            transformers.append((\"abv\", RobustScaler(), [\"abv\"]))\n",
        "        if \"name\" in feature_set:\n",
        "            transformers.append((\"name_tfidf\", TfidfVectorizer(max_features=100), \"name\"))\n",
        "        if \"available\" in feature_set:\n",
        "            transformers.append((\"available_ohe\", OneHotEncoder(handle_unknown='ignore'), [\"available\"]))\n",
        "        if \"glass\" in feature_set:\n",
        "            transformers.append((\"glass_ohe\", OneHotEncoder(handle_unknown='ignore'), [\"glass\"]))\n",
        "        if \"description\" in feature_set:\n",
        "            transformers.append((\"description_tfidf\", TfidfVectorizer(max_features=100), \"description\"))\n",
        "        if \"originalGravity\" in feature_set:\n",
        "            transformers.append((\"originalGravity\", RobustScaler(), [\"originalGravity\"]))\n",
        "        if \"srm\" in feature_set:\n",
        "            transformers.append((\"srm\", RobustScaler(), [\"srm\"]))\n",
        "        if \"isOrganic\" in feature_set:\n",
        "            transformers.append((\"isOrganic_ohe\", OneHotEncoder(handle_unknown='ignore'), [\"isOrganic\"]))\n",
        "\n",
        "        preprocessor = ColumnTransformer(transformers, remainder='drop')\n",
        "\n",
        "        pipeline = Pipeline(steps=[\n",
        "            (\"preprocessor\", preprocessor),\n",
        "            (\"model\", model)\n",
        "        ])\n",
        "\n",
        "        param_grid = param_grids[model_name]\n",
        "\n",
        "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "        X = data[feature_set].copy()\n",
        "        y = data[target]\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        best_params = grid_search.best_params_\n",
        "        best_score = -grid_search.best_score_\n",
        "        best_rmse = np.sqrt(best_score)\n",
        "\n",
        "        results[(model_name, tuple(feature_set))] = (best_score, best_rmse, best_params)\n"
      ],
      "metadata": {
        "id": "gV-zcphZjIQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for (model_name, feature_set), (mse, rmse, best_params) in results.items():\n",
        "    print(f\"Model: {model_name}, Features: {feature_set}, MSE: {mse:.2f}, RMSE: {rmse:.2f}, Best Params: {best_params}\")\n",
        "\n",
        "best_model_features = min(results, key=lambda x: results[x][0])\n",
        "best_model_name, best_features = best_model_features\n",
        "best_mse, best_rmse, best_params = results[best_model_features]\n",
        "print(f\"\\nBest Model: {best_model_name}, Features: {best_features}, MSE: {best_mse:.2f}, RMSE: {best_rmse:.2f}, Best Params: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDvR0H9jLqr",
        "outputId": "8e257adf-64d3-4d8a-9224-9b84b11ceb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LinearRegression, Features: ('abv',), MSE: 507.99, RMSE: 22.54, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name'), MSE: 378.85, RMSE: 19.46, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name', 'available'), MSE: 379.56, RMSE: 19.48, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name', 'available', 'glass'), MSE: 372.12, RMSE: 19.29, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name', 'description'), MSE: 312.10, RMSE: 17.67, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 312.09, RMSE: 17.67, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'originalGravity'), MSE: 480.93, RMSE: 21.93, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'srm'), MSE: 504.38, RMSE: 22.46, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'isOrganic'), MSE: 507.71, RMSE: 22.53, Best Params: {}\n",
            "Model: LinearRegression, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 302.94, RMSE: 17.41, Best Params: {}\n",
            "Model: Ridge, Features: ('abv',), MSE: 507.99, RMSE: 22.54, Best Params: {'model__alpha': 10.0}\n",
            "Model: Ridge, Features: ('abv', 'name'), MSE: 377.63, RMSE: 19.43, Best Params: {'model__alpha': 1.0}\n",
            "Model: Ridge, Features: ('abv', 'name', 'available'), MSE: 378.30, RMSE: 19.45, Best Params: {'model__alpha': 1.0}\n",
            "Model: Ridge, Features: ('abv', 'name', 'available', 'glass'), MSE: 370.61, RMSE: 19.25, Best Params: {'model__alpha': 1.0}\n",
            "Model: Ridge, Features: ('abv', 'name', 'description'), MSE: 304.73, RMSE: 17.46, Best Params: {'model__alpha': 10.0}\n",
            "Model: Ridge, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 302.94, RMSE: 17.41, Best Params: {'model__alpha': 10.0}\n",
            "Model: Ridge, Features: ('abv', 'originalGravity'), MSE: 480.92, RMSE: 21.93, Best Params: {'model__alpha': 10.0}\n",
            "Model: Ridge, Features: ('abv', 'srm'), MSE: 504.38, RMSE: 22.46, Best Params: {'model__alpha': 10.0}\n",
            "Model: Ridge, Features: ('abv', 'isOrganic'), MSE: 507.71, RMSE: 22.53, Best Params: {'model__alpha': 1.0}\n",
            "Model: Ridge, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 295.53, RMSE: 17.19, Best Params: {'model__alpha': 10.0}\n",
            "Model: Lasso, Features: ('abv',), MSE: 508.00, RMSE: 22.54, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name'), MSE: 408.63, RMSE: 20.21, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name', 'available'), MSE: 408.29, RMSE: 20.21, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name', 'available', 'glass'), MSE: 398.18, RMSE: 19.95, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name', 'description'), MSE: 327.95, RMSE: 18.11, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 324.74, RMSE: 18.02, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'originalGravity'), MSE: 480.93, RMSE: 21.93, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'srm'), MSE: 504.41, RMSE: 22.46, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'isOrganic'), MSE: 508.00, RMSE: 22.54, Best Params: {'model__alpha': 0.1}\n",
            "Model: Lasso, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 318.81, RMSE: 17.86, Best Params: {'model__alpha': 0.1}\n",
            "Model: ElasticNet, Features: ('abv',), MSE: 508.05, RMSE: 22.54, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name'), MSE: 416.89, RMSE: 20.42, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name', 'available'), MSE: 416.25, RMSE: 20.40, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name', 'available', 'glass'), MSE: 405.05, RMSE: 20.13, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name', 'description'), MSE: 346.65, RMSE: 18.62, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 342.28, RMSE: 18.50, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'originalGravity'), MSE: 480.93, RMSE: 21.93, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'srm'), MSE: 504.47, RMSE: 22.46, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'isOrganic'), MSE: 508.05, RMSE: 22.54, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: ElasticNet, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 336.47, RMSE: 18.34, Best Params: {'model__alpha': 0.1, 'model__l1_ratio': 0.9}\n",
            "Model: DecisionTreeRegressor, Features: ('abv',), MSE: 574.65, RMSE: 23.97, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name'), MSE: 417.32, RMSE: 20.43, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name', 'available'), MSE: 420.65, RMSE: 20.51, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name', 'available', 'glass'), MSE: 419.08, RMSE: 20.47, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name', 'description'), MSE: 503.17, RMSE: 22.43, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 471.26, RMSE: 21.71, Best Params: {'model__max_depth': 20}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'originalGravity'), MSE: 448.98, RMSE: 21.19, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'srm'), MSE: 582.70, RMSE: 24.14, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'isOrganic'), MSE: 575.61, RMSE: 23.99, Best Params: {'model__max_depth': 5}\n",
            "Model: DecisionTreeRegressor, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 376.46, RMSE: 19.40, Best Params: {'model__max_depth': 10}\n",
            "Model: RandomForestRegressor, Features: ('abv',), MSE: 512.72, RMSE: 22.64, Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name'), MSE: 414.90, RMSE: 20.37, Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name', 'available'), MSE: 400.49, RMSE: 20.01, Best Params: {'model__max_depth': 10, 'model__n_estimators': 200}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name', 'available', 'glass'), MSE: 390.35, RMSE: 19.76, Best Params: {'model__max_depth': 10, 'model__n_estimators': 100}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name', 'description'), MSE: 291.36, RMSE: 17.07, Best Params: {'model__max_depth': 20, 'model__n_estimators': 100}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 286.49, RMSE: 16.93, Best Params: {'model__max_depth': 20, 'model__n_estimators': 200}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'originalGravity'), MSE: 390.90, RMSE: 19.77, Best Params: {'model__max_depth': 5, 'model__n_estimators': 100}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'srm'), MSE: 460.19, RMSE: 21.45, Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'isOrganic'), MSE: 516.02, RMSE: 22.72, Best Params: {'model__max_depth': 5, 'model__n_estimators': 100}\n",
            "Model: RandomForestRegressor, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 287.25, RMSE: 16.95, Best Params: {'model__max_depth': 20, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv',), MSE: 497.20, RMSE: 22.30, Best Params: {'model__learning_rate': 0.01, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name'), MSE: 399.35, RMSE: 19.98, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 100}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name', 'available'), MSE: 378.64, RMSE: 19.46, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name', 'available', 'glass'), MSE: 380.41, RMSE: 19.50, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 100}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name', 'description'), MSE: 288.81, RMSE: 16.99, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 277.85, RMSE: 16.67, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'originalGravity'), MSE: 405.89, RMSE: 20.15, Best Params: {'model__learning_rate': 0.01, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'srm'), MSE: 452.91, RMSE: 21.28, Best Params: {'model__learning_rate': 0.01, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'isOrganic'), MSE: 497.17, RMSE: 22.30, Best Params: {'model__learning_rate': 0.01, 'model__n_estimators': 200}\n",
            "Model: GradientBoostingRegressor, Features: ('abv', 'name', 'description', 'originalGravity', 'srm', 'isOrganic'), MSE: 284.63, RMSE: 16.87, Best Params: {'model__learning_rate': 0.2, 'model__n_estimators': 200}\n",
            "\n",
            "Best Model: GradientBoostingRegressor, Features: ('abv', 'name', 'available', 'glass', 'description'), MSE: 277.85, RMSE: 16.67, Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models[best_model_name]\n",
        "best_params = {k.split('__')[-1]: v for k, v in best_params.items()}\n",
        "print(best_params)\n",
        "best_features = list(best_features)\n",
        "\n",
        "transformers = [\n",
        "    (\"abv\", RobustScaler(), [\"abv\"]),\n",
        "    (\"name_tfidf\", TfidfVectorizer(max_features=100), \"name\"),\n",
        "    (\"available_ohe\", OneHotEncoder(handle_unknown='ignore'), [\"available\"]),\n",
        "    (\"glass_ohe\", OneHotEncoder(handle_unknown='ignore'), [\"glass\"]),\n",
        "    (\"description_tfidf\", TfidfVectorizer(max_features=100), \"description\"),\n",
        "]\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", ColumnTransformer(transformers, remainder='drop')),\n",
        "    (\"model\", best_model.set_params(**best_params))\n",
        "])\n",
        "\n",
        "print(best_features)\n",
        "print(target)\n",
        "X = data[best_features].copy()\n",
        "y = data[target]\n",
        "\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "test_data.dropna(subset=best_features, inplace=True)\n",
        "X_test = test_data[best_features].copy()\n",
        "\n",
        "predictions = pipeline.predict(X_test)\n",
        "\n",
        "test_data['ibu'] = predictions\n",
        "\n",
        "submission = test_data[['id', 'ibu']]\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fR6UzS7T2ly",
        "outputId": "26bde194-35ac-4005-9ba8-17fb496dae37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.1, 'n_estimators': 200}\n",
            "['abv', 'name', 'available', 'glass', 'description']\n",
            "ibu\n",
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q58pPwmEt_n9"
      },
      "source": [
        "\n",
        "## Question 2\n",
        "\n",
        "_This question should be done late in the competition, after you have already made several submissions to Kaggle._\n",
        "\n",
        "In class, we discussed \"ensemble methods\", which are methods for combining predictions from different machine learning models. One simple method of ensembling regression models is to take a straight average of the predictions from the models. Work with another team, average the predictions from your best model and their best model, and upload the resulting predictions to Kaggle. Look at your RMSE on the public leaderboard. How does the test RMSE of the ensemble model compare to the test RMSEs of the individual models?\n",
        "\n",
        "(_Note:_ You are not required to evaluate the ensemble model using cross-validation. Just report the RMSE from Kaggle.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('my_submission.csv')\n",
        "df2 = pd.read_csv('other.csv')\n",
        "\n",
        "merged_df = pd.merge(df1, df2, on='id', suffixes=('_mine', '_other'))\n",
        "merged_df['ibu'] = (merged_df['ibu_mine'] + merged_df['ibu_other']) / 2\n",
        "merged_df.drop(columns=['ibu_mine', 'ibu_other'], inplace=True)\n",
        "merged_df.to_csv('ensemble_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "T6TJIzbwA00L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After averaging predictions from my best model and another person's best model, I uploaded the results and I got a slightly better model performance/accuracy by 3.84728% from 20.82356 to 20.03754."
      ],
      "metadata": {
        "id": "wpYtlD17CMM2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmem3ubTtYUY"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "- Restart this notebook and run the cells from beginning to end:\n",
        "  - Go to Runtime > Restart and Run All.\n",
        "- Download the notebook:\n",
        "  - Go to File > Download > Download .ipynb.\n",
        "- Submit your notebook file to the assignment on Canvas."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ag8jS9mVYXLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}